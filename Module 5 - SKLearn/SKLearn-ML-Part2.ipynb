{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SCIKIT-LEARN or SKLEARN #####\n",
    "#\n",
    "#  - Python Machine Learning Module\n",
    "#  - Simple and efficient tools for data mining and data analysis\n",
    "#  - Accessible to everybody, and reusable in various contexts\n",
    "#  - Built on NumPy, SciPy, and matplotlib\n",
    "#  - Open source, commercially usable - BSD license\n",
    "#\n",
    "# https://scikit-learn.org/stable/index.html\n",
    "# https://scikit-learn.org/stable/user_guide.html \n",
    "# https://scikit-learn.org/stable/modules/classes.html\n",
    "# https://scikit-learn.org/stable/auto_examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sklearn ML API is very consistent:\n",
    "# 0) read data\n",
    "# 1) explore data\n",
    "# 2) preprocess data\n",
    "# 3) setup data for consumption by ML model \n",
    "#     4) choose the model by importing the appropriate estiamtor class from sklearn [from sklearn import model]\n",
    "#     5) instantiate the model with desired parameter values [ml=model()]\n",
    "#     6) fit the model to the training data [ml.fit(Xtrain, ytrain)]\n",
    "#     7) apply the model to test data [ypred=ml.predict(Xtest) or ml.transform(Xtest)]\n",
    "# 8) evaluate model\n",
    "# 9) deploy/use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Logistic Regression\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#\n",
    " \n",
    "# 0) read data\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['label'] = dataset.target\n",
    "df.head()\n",
    "\n",
    "# 1) explore data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 2) preprocess data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 3) setup data for ml model\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 4-7) import, instantiate, train, test model\n",
    "from sklearn.linear_model import LogisticRegression                                                                   # 4) choose the model \n",
    "lr = LogisticRegression(C=1e5, solver='lbfgs', multi_class='auto', class_weight=None)                # 5) instantiate the model \n",
    "lr.fit(X_train, y_train)                                                                                                                         # 6) fit the model to train data\n",
    "y_pred = lr.predict(X_test)                                                                                                                # 7) apply model to test data \n",
    "\n",
    "# 8) evaluate model\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2257421e048>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### KNN Classification\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/neighbors.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "#\n",
    "\n",
    "# 0) read data\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['label'] = dataset.target\n",
    "df.head()\n",
    "\n",
    "# 1) explore data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 2) preprocess data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 3) setup data for ml model\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 4-7) import, instantiate, train, test model\n",
    "from sklearn.neighbors import KNeighborsClassifier                                                            \n",
    "# simple majority vote (weights='uniform') of 5 nearest neighbors (n_neighbors=5) based on euclidean distance (p=2, metric='minkowski')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', p=2, metric='minkowski') \n",
    "knn.fit(X_train, y_train)                                                                                                            \n",
    "y_pred = knn.predict(X_test)                                                                                                  \n",
    "\n",
    "# 8) evaluate model\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Note, we can use the \"elbow method\" to pick an optimal k \n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "errorlst = pd.DataFrame(data=None, columns=['k','error'])\n",
    "for k in range(1,5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error = metrics.mean_absolute_error (y_test, y_pred)\n",
    "    errorlst = errorlst.append ({'k':k, 'error':error}, ignore_index=True)\n",
    "plt.plot (errorlst['k'], errorlst['error'], 'o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### SVM Classification\n",
    "# \n",
    "# https://scikit-learn.org/stable/modules/svm.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "# https://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "#\n",
    "\n",
    "# 0) read data\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['label'] = dataset.target\n",
    "df.head()\n",
    "\n",
    "# 1) explore data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 2) preprocess data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 3) setup data for ml model\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 4-7) import, instantiate, train, test model\n",
    "from sklearn.svm import SVC                                          \n",
    "svc = SVC(C=1.0, kernel='linear', class_weight=None)     \n",
    "# svc = SVC(C=1.0, kernel='rbf', gamma=0.7)\n",
    "# svc = SVC(C=1.0, kernel='poly', degree=3)\n",
    "svc.fit(X_train, y_train)                                                        \n",
    "y_pred = svc.predict(X_test)                                               \n",
    "\n",
    "# 8) evaluate model\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Naive Bayes Classification\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "#\n",
    "\n",
    "# 0) read data\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['label'] = dataset.target\n",
    "df.head()\n",
    "\n",
    "# 1) explore data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 2) preprocess data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 3) setup data for ml model\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 4-7) import, instantiate, train, test model\n",
    "from sklearn.naive_bayes import GaussianNB            \n",
    "nb = GaussianNB()                                                       \n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# nb = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)                                                   \n",
    "y_pred = nb.predict(X_test)                                         \n",
    "\n",
    "# 8) evaluate model\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Decision Tree Classification\n",
    "#\n",
    "# https://scikit-learn.org/stable/modules/tree.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "#\n",
    "\n",
    "# 0) read data\n",
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['label'] = dataset.target\n",
    "df.head()\n",
    "\n",
    "# 1) explore data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 2) preprocess data\n",
    "# not demonstrating for this example\n",
    "\n",
    "# 3) setup data for ml model\n",
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# 4-7) import, instantiate, train, test model\n",
    "from sklearn.tree import DecisionTreeClassifier            \n",
    "dt = DecisionTreeClassifier(max_depth=None, min_samples_split=2, min_samples_leaf=1, class_weight=None)                                           \n",
    "dt.fit(X_train, y_train)                                                       \n",
    "y_pred = dt.predict(X_test)                                             \n",
    "\n",
    "# 8) evaluate model\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(y_test, y_pred))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))\n",
    "print (metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
